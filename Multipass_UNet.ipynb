{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycBn2z_xNttX",
        "outputId": "3044735d-3ced-42e8-8c46-3fd0c7433d6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK, pydicom\n",
            "Successfully installed SimpleITK-2.4.1 pydicom-3.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom matplotlib numpy SimpleITK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FAHd-0nNvo7",
        "outputId": "35385e06-d2e6-452c-ba83-9fb595599e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "!wget https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n",
        "!tar -xvzf dcmqi-1.2.5-linux.tar.gz\n",
        "DCMQI_BIN = \"/content/dcmqi-1.2.5-linux/bin/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MKV2u-NOSDT",
        "outputId": "c75465cc-6ee5-4d6e-c1df-7b98e983c238"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-08 06:19:30--  https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/79d3ad95-9f0c-42a4-a1c5-bf5a63461894?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250308T061930Z&X-Amz-Expires=300&X-Amz-Signature=1bface6dea7b561dbd7b482560059751534554cc0761b6af665643525454e424&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.5-linux.tar.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-03-08 06:19:30--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/50675718/79d3ad95-9f0c-42a4-a1c5-bf5a63461894?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250308%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250308T061930Z&X-Amz-Expires=300&X-Amz-Signature=1bface6dea7b561dbd7b482560059751534554cc0761b6af665643525454e424&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Ddcmqi-1.2.5-linux.tar.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21102129 (20M) [application/octet-stream]\n",
            "Saving to: ‘dcmqi-1.2.5-linux.tar.gz’\n",
            "\n",
            "dcmqi-1.2.5-linux.t 100%[===================>]  20.12M  87.1MB/s    in 0.2s    \n",
            "\n",
            "2025-03-08 06:19:31 (87.1 MB/s) - ‘dcmqi-1.2.5-linux.tar.gz’ saved [21102129/21102129]\n",
            "\n",
            "dcmqi-1.2.5-linux/bin/\n",
            "dcmqi-1.2.5-linux/bin/itkimage2segimage\n",
            "dcmqi-1.2.5-linux/bin/tid1500reader\n",
            "dcmqi-1.2.5-linux/bin/tid1500reader.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2segimage.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2paramap.xml\n",
            "dcmqi-1.2.5-linux/bin/itkimage2paramap\n",
            "dcmqi-1.2.5-linux/bin/segimage2itkimage.xml\n",
            "dcmqi-1.2.5-linux/bin/segimage2itkimage\n",
            "dcmqi-1.2.5-linux/bin/tid1500writer.xml\n",
            "dcmqi-1.2.5-linux/bin/tid1500writer\n",
            "dcmqi-1.2.5-linux/bin/paramap2itkimage\n",
            "dcmqi-1.2.5-linux/bin/paramap2itkimage.xml\n",
            "dcmqi-1.2.5-linux/share/\n",
            "dcmqi-1.2.5-linux/share/doc/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/itksys/\n",
            "dcmqi-1.2.5-linux/share/doc/ITK-4.10/itksys/Copyright.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import SimpleITK as sitk\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pad_to_depth(x, target_depth):\n",
        "\n",
        "    current_depth = x.shape[1]\n",
        "    if current_depth < target_depth:\n",
        "        pad_amount = target_depth - current_depth\n",
        "        pad_tensor = torch.zeros(x.shape[0], pad_amount, x.shape[2], x.shape[3],\n",
        "                                   device=x.device, dtype=x.dtype)\n",
        "        x = torch.cat([x, pad_tensor], dim=1)\n",
        "    return x\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Pads the CT and segmentation tensors in the batch along the depth dimension.\n",
        "    Each sample is a dict with keys 'ct' and 'seg' (each of shape (1, D, H, W)).\n",
        "    \"\"\"\n",
        "    max_depth = max(sample['ct'].shape[1] for sample in batch)\n",
        "    for sample in batch:\n",
        "        sample['ct'] = pad_to_depth(sample['ct'], max_depth)\n",
        "        sample['seg'] = pad_to_depth(sample['seg'], max_depth)\n",
        "    batch_ct = torch.stack([sample['ct'] for sample in batch])\n",
        "    batch_seg = torch.stack([sample['seg'] for sample in batch])\n",
        "    return {'ct': batch_ct, 'seg': batch_seg}\n",
        "\n",
        "# -----------------------\n",
        "# Conversion Function\n",
        "# -----------------------\n",
        "def convert_seg_dicom_to_mha(im1_path, im3_path, output_dir):\n",
        "    \"\"\"\n",
        "    Convert a DICOM segmentation in im3_path into .mha format using dcmqi.\n",
        "    The resulting .mha file is saved into output_dir (the patient folder).\n",
        "\n",
        "    :param im1_path: Path to the folder containing CT DICOM slices (e.g., 'im_1')\n",
        "    :param im3_path: Path to the folder containing segmentation DICOM files (e.g., 'im_3')\n",
        "    :param output_dir: Patient folder where the .mha file should be saved.\n",
        "    :return: Path to the created .mha file, or None if conversion fails.\n",
        "    \"\"\"\n",
        "    # Install dcmqi (if not already installed)\n",
        "    !pip install --quiet dcmqi\n",
        "\n",
        "    # Download and unpack dcmqi binaries if needed\n",
        "    if not os.path.exists(\"dcmqi-1.2.5-linux\"):\n",
        "        !wget --quiet https://github.com/QIICR/dcmqi/releases/download/v1.2.5/dcmqi-1.2.5-linux.tar.gz\n",
        "        !tar -xvzf dcmqi-1.2.5-linux.tar.gz\n",
        "\n",
        "    dcmqi_bin = os.path.join(os.getcwd(), \"dcmqi-1.2.5-linux\", \"bin\")\n",
        "\n",
        "    # Find the segmentation DICOM file in im3_path\n",
        "    seg_dcm_files = [f for f in os.listdir(im3_path) if f.lower().endswith(\".dcm\")]\n",
        "    if not seg_dcm_files:\n",
        "        print(f\"No segmentation DICOM file found in {im3_path}.\")\n",
        "        return None\n",
        "\n",
        "    seg_dicom_path = os.path.join(im3_path, seg_dcm_files[0])\n",
        "\n",
        "    # Ensure the output directory exists (output_dir is the patient folder)\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Build and run the conversion command\n",
        "    convert_cmd = [\n",
        "        os.path.join(dcmqi_bin, \"segimage2itkimage\"),\n",
        "        \"--inputDICOM\", seg_dicom_path,\n",
        "        \"--outputDirectory\", output_dir,\n",
        "        \"-t\", \"mha\",\n",
        "        \"-p\", \"segmentation\"\n",
        "    ]\n",
        "\n",
        "    print(\"Running dcmqi conversion command:\\n\", \" \".join(convert_cmd))\n",
        "    result = subprocess.run(convert_cmd, capture_output=True, text=True)\n",
        "    if result.returncode != 0:\n",
        "        print(\"Conversion failed. Error:\\n\", result.stderr)\n",
        "        return None\n",
        "\n",
        "    # Look for the created .mha file (e.g., 'segmentation-1.mha') in the patient folder\n",
        "    mha_files = [f for f in os.listdir(output_dir) if f.startswith(\"segmentation\") and f.endswith(\".mha\")]\n",
        "    if not mha_files:\n",
        "        print(f\"No .mha file was created in {output_dir}.\")\n",
        "        return None\n",
        "\n",
        "    mha_path = os.path.join(output_dir, mha_files[0])\n",
        "    print(f\"Created .mha file: {mha_path}\")\n",
        "    return mha_path\n",
        "\n",
        "# -----------------------\n",
        "# Data Processing Functions\n",
        "# -----------------------\n",
        "def get_patient_folders(root_path):\n",
        "    \"\"\"\n",
        "    Returns a list of directories under root_path that contain an 'im_1' subfolder.\n",
        "    These directories are assumed to be patient folders.\n",
        "    \"\"\"\n",
        "    patient_folders = []\n",
        "    for entry in os.listdir(root_path):\n",
        "        full_path = os.path.join(root_path, entry)\n",
        "        if os.path.isdir(full_path) and os.path.exists(os.path.join(full_path, \"im_1\")):\n",
        "            patient_folders.append(full_path)\n",
        "    return patient_folders\n",
        "\n",
        "import threading\n",
        "\n",
        "def get_dicom_series(directory, timeout=60):\n",
        "    \"\"\"\n",
        "    Loads a DICOM series from a directory with a timeout.\n",
        "    If loading takes longer than 'timeout' seconds, the function skips the series.\n",
        "    \"\"\"\n",
        "    reader = sitk.ImageSeriesReader()\n",
        "    series_IDs = reader.GetGDCMSeriesIDs(directory)\n",
        "\n",
        "    if not series_IDs:\n",
        "        print(f\"No DICOM series found in {directory}.\")\n",
        "        return None\n",
        "\n",
        "    dicom_files = reader.GetGDCMSeriesFileNames(directory, series_IDs[0])\n",
        "    reader.SetFileNames(dicom_files)\n",
        "\n",
        "    # Result placeholder\n",
        "    result = [None]\n",
        "\n",
        "    def load_dicom():\n",
        "        try:\n",
        "            result[0] = reader.Execute()\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading DICOM series from {directory}: {e}\")\n",
        "            result[0] = None\n",
        "\n",
        "    # Create a thread to run the DICOM loading process\n",
        "    load_thread = threading.Thread(target=load_dicom)\n",
        "    load_thread.start()\n",
        "\n",
        "    # Wait for the thread to finish within the timeout\n",
        "    load_thread.join(timeout)\n",
        "\n",
        "    if load_thread.is_alive():\n",
        "        print(f\"Skipping {directory} due to timeout (took longer than {timeout} seconds).\")\n",
        "        return None\n",
        "\n",
        "    return result[0]\n",
        "\n",
        "def process_files():\n",
        "    \"\"\"\n",
        "    Processes patient folders under \"My Drive\" and stops after 25 patients.\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "    target_shape = (128, 128, 72)\n",
        "    base_path = \"/content/drive/My Drive/\"\n",
        "    patients = get_patient_folders(base_path)\n",
        "\n",
        "    if not patients:\n",
        "        print(\"No patient folders found under My Drive.\")\n",
        "        return processed_data\n",
        "\n",
        "    count = 0  # Counter to track processed files\n",
        "    max_files = 25  # Limit processing to 25 files\n",
        "\n",
        "    for patient in patients:\n",
        "        if count >= max_files:\n",
        "            print(\"\\nReached the limit of 25 processed files. Stopping.\")\n",
        "            break\n",
        "\n",
        "        print(f\"\\nProcessing patient folder: {patient}\")\n",
        "\n",
        "        ct_path = os.path.join(patient, \"im_1\")\n",
        "        seg_path = os.path.join(patient, \"im_3\")\n",
        "\n",
        "        # Load CT series from im_1\n",
        "        ct_image = get_dicom_series(ct_path)\n",
        "        if ct_image is None:\n",
        "            print(f\"Skipping {patient}: No DICOM series found in im_1.\")\n",
        "            continue\n",
        "\n",
        "        ct_volume = sitk.GetArrayFromImage(ct_image)\n",
        "        print(f\"Original CT Shape: {ct_volume.shape}\")\n",
        "\n",
        "        # Process segmentation from im_3\n",
        "        if not os.path.exists(seg_path):\n",
        "            print(f\"Skipping {patient}: No im_3 folder found.\")\n",
        "            continue\n",
        "\n",
        "        # Look for an existing .mha segmentation file in im_3\n",
        "        seg_files = [f for f in os.listdir(seg_path) if f.endswith(\".mha\")]\n",
        "        if not seg_files:\n",
        "            print(f\"No .mha segmentation file found in im_3 for {patient}. Attempting conversion...\")\n",
        "            mha_file = convert_seg_dicom_to_mha(ct_path, seg_path, patient)\n",
        "            if mha_file is None:\n",
        "                print(f\"Conversion failed for {patient}. Skipping.\")\n",
        "                continue\n",
        "            else:\n",
        "                seg_file_path = mha_file\n",
        "        else:\n",
        "            seg_file_path = os.path.join(seg_path, seg_files[0])\n",
        "\n",
        "        # Load segmentation image\n",
        "        seg_image = sitk.ReadImage(seg_file_path)\n",
        "        seg_volume = sitk.GetArrayFromImage(seg_image)\n",
        "        print(f\"Original Segmentation Shape: {seg_volume.shape}\")\n",
        "\n",
        "        # Resample segmentation if dimensions differ from the CT volume\n",
        "        if seg_volume.shape != ct_volume.shape:\n",
        "            print(\"Resampling segmentation to match CT dimensions...\")\n",
        "            seg_tensor = torch.tensor(seg_volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "            seg_resampled = F.interpolate(seg_tensor, size=ct_volume.shape, mode='nearest')\n",
        "            seg_volume = seg_resampled.squeeze().numpy().astype(np.uint8)\n",
        "            print(f\"Resampled Segmentation Shape: {seg_volume.shape}\")\n",
        "\n",
        "        # Downsample CT and segmentation to target shape\n",
        "        ct_tensor = torch.tensor(ct_volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "        ct_resized = F.interpolate(ct_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
        "        ct_volume_resized = ct_resized.squeeze().numpy()\n",
        "\n",
        "        seg_tensor = torch.tensor(seg_volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "        seg_resized = F.interpolate(seg_tensor, size=target_shape, mode='nearest')\n",
        "        seg_volume_resized = seg_resized.squeeze().numpy().astype(np.uint8)\n",
        "\n",
        "        print(f\"Downsampled CT Shape: {ct_volume_resized.shape}\")\n",
        "        print(f\"Downsampled Segmentation Shape: {seg_volume_resized.shape}\")\n",
        "\n",
        "        processed_data.append({\n",
        "            \"filename\": patient,\n",
        "            \"ct_volume\": ct_volume_resized,\n",
        "            \"segmentation\": seg_volume_resized,\n",
        "            \"spacing\": ct_image.GetSpacing()[::-1],  # (Depth, Height, Width)\n",
        "            \"origin\": ct_image.GetOrigin()\n",
        "        })\n",
        "\n",
        "        count += 1  # Increment counter\n",
        "\n",
        "    print(\"\\nProcessing complete!\")\n",
        "    print(f\"Processed {len(processed_data)} datasets successfully.\")\n",
        "    return processed_data\n",
        "\n",
        "# -----------------------\n",
        "# Main Execution\n",
        "# -----------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Run the processing pipeline over all patient folders in My Drive\n",
        "processed_data = process_files()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NwkP5rUDD08K",
        "outputId": "3289096b-c6e7-45ab-956b-a16edee5580b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/0A44743795D421F7\n",
            "Original CT Shape: (520, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/0A44743795D421F7. Attempting conversion...\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.4/40.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRunning dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/0A44743795D421F7/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/0A44743795D421F7 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/0A44743795D421F7/segmentation-1.mha\n",
            "Original Segmentation Shape: (246, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (520, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/0AD7CE889B4FB16F\n",
            "Original CT Shape: (501, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/0AD7CE889B4FB16F. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/0AD7CE889B4FB16F/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/0AD7CE889B4FB16F -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/0AD7CE889B4FB16F/segmentation-1.mha\n",
            "Original Segmentation Shape: (263, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (501, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/0D0C5A034B94C222\n",
            "Original CT Shape: (578, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/0D0C5A034B94C222. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/0D0C5A034B94C222/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/0D0C5A034B94C222 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/0D0C5A034B94C222/segmentation-3.mha\n",
            "Original Segmentation Shape: (298, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (578, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/0FC3188AAA7E6851\n",
            "Original CT Shape: (538, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/0FC3188AAA7E6851. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/0FC3188AAA7E6851/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/0FC3188AAA7E6851 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/0FC3188AAA7E6851/segmentation-2.mha\n",
            "Original Segmentation Shape: (268, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (538, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/1D1D8ECAC96EFAA5\n",
            "Original CT Shape: (617, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/1D1D8ECAC96EFAA5. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/1D1D8ECAC96EFAA5/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/1D1D8ECAC96EFAA5 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/1D1D8ECAC96EFAA5/segmentation-2.mha\n",
            "Original Segmentation Shape: (297, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (617, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/02CC41B35F6C8145\n",
            "Original CT Shape: (524, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/02CC41B35F6C8145. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/02CC41B35F6C8145/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/02CC41B35F6C8145 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/02CC41B35F6C8145/segmentation-1.mha\n",
            "Original Segmentation Shape: (266, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (524, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/2DD9A1B65346D271\n",
            "Original CT Shape: (717, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/2DD9A1B65346D271. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/2DD9A1B65346D271/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/2DD9A1B65346D271 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/2DD9A1B65346D271/segmentation-1.mha\n",
            "Original Segmentation Shape: (281, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (717, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/3B3256E6694B0ABE\n",
            "Original CT Shape: (514, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/3B3256E6694B0ABE. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/3B3256E6694B0ABE/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/3B3256E6694B0ABE -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/3B3256E6694B0ABE/segmentation-3.mha\n",
            "Original Segmentation Shape: (264, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (514, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/3E934A9F0D559A6F\n",
            "Original CT Shape: (501, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/3E934A9F0D559A6F. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/3E934A9F0D559A6F/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/3E934A9F0D559A6F -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/3E934A9F0D559A6F/segmentation-1.mha\n",
            "Original Segmentation Shape: (250, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (501, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/3F2E8686E524ABCA\n",
            "Original CT Shape: (578, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/3F2E8686E524ABCA. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/3F2E8686E524ABCA/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/3F2E8686E524ABCA -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/3F2E8686E524ABCA/segmentation-4.mha\n",
            "Original Segmentation Shape: (297, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (578, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/4CD9674D8668698C\n",
            "Original CT Shape: (588, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/4CD9674D8668698C. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/4CD9674D8668698C/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/4CD9674D8668698C -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/4CD9674D8668698C/segmentation-3.mha\n",
            "Original Segmentation Shape: (271, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (588, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/5A48C85404AB8CFD\n",
            "Original CT Shape: (545, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/5A48C85404AB8CFD. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/5A48C85404AB8CFD/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/5A48C85404AB8CFD -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/5A48C85404AB8CFD/segmentation-3.mha\n",
            "Original Segmentation Shape: (260, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (545, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/5B6D4F35387FF59C\n",
            "Original CT Shape: (712, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/5B6D4F35387FF59C. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/5B6D4F35387FF59C/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/5B6D4F35387FF59C -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/5B6D4F35387FF59C/segmentation-1.mha\n",
            "Original Segmentation Shape: (267, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (712, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/5F3E9A19B47C2EAD\n",
            "Original CT Shape: (709, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/5F3E9A19B47C2EAD. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/5F3E9A19B47C2EAD/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/5F3E9A19B47C2EAD -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/5F3E9A19B47C2EAD/segmentation-1.mha\n",
            "Original Segmentation Shape: (253, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (709, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/06BE6C20741AFADD\n",
            "Original CT Shape: (568, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/06BE6C20741AFADD. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/06BE6C20741AFADD/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/06BE6C20741AFADD -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/06BE6C20741AFADD/segmentation-1.mha\n",
            "Original Segmentation Shape: (280, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (568, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/7A84C4C355AAF522\n",
            "Original CT Shape: (501, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/7A84C4C355AAF522. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/7A84C4C355AAF522/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/7A84C4C355AAF522 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/7A84C4C355AAF522/segmentation-4.mha\n",
            "Original Segmentation Shape: (275, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (501, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/7D8E6E1C05D04B9D\n",
            "Skipping /content/drive/My Drive/7D8E6E1C05D04B9D/im_1 due to timeout (took longer than 60 seconds).\n",
            "Skipping /content/drive/My Drive/7D8E6E1C05D04B9D: No DICOM series found in im_1.\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/08D745849406C9D5\n",
            "Original CT Shape: (579, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/08D745849406C9D5. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/08D745849406C9D5/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/08D745849406C9D5 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/08D745849406C9D5/segmentation-3.mha\n",
            "Original Segmentation Shape: (242, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (579, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/083B371B51E8CC0B\n",
            "Original CT Shape: (631, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/083B371B51E8CC0B. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/083B371B51E8CC0B/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/083B371B51E8CC0B -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/083B371B51E8CC0B/segmentation-1.mha\n",
            "Original Segmentation Shape: (202, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (631, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/11BC311A21A22818\n",
            "Original CT Shape: (679, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/11BC311A21A22818. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/11BC311A21A22818/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/11BC311A21A22818 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/11BC311A21A22818/segmentation-2.mha\n",
            "Original Segmentation Shape: (249, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (679, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/08FF8BEBB1FB756A\n",
            "Original CT Shape: (642, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/08FF8BEBB1FB756A. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/08FF8BEBB1FB756A/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/08FF8BEBB1FB756A -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/08FF8BEBB1FB756A/segmentation-3.mha\n",
            "Original Segmentation Shape: (222, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (642, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/339F7F1A6EF6ED24\n",
            "Original CT Shape: (508, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/339F7F1A6EF6ED24. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/339F7F1A6EF6ED24/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/339F7F1A6EF6ED24 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/339F7F1A6EF6ED24/segmentation-2.mha\n",
            "Original Segmentation Shape: (260, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (508, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/26DD3530EC0566E9\n",
            "Original CT Shape: (611, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/26DD3530EC0566E9. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/26DD3530EC0566E9/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/26DD3530EC0566E9 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/26DD3530EC0566E9/segmentation-1.mha\n",
            "Original Segmentation Shape: (265, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (611, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/47DF7844DE611A35\n",
            "Original CT Shape: (525, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/47DF7844DE611A35. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/47DF7844DE611A35/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/47DF7844DE611A35 -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/47DF7844DE611A35/segmentation-2.mha\n",
            "Original Segmentation Shape: (257, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (525, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/186C2C2E731D073F\n",
            "Original CT Shape: (501, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/186C2C2E731D073F. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/186C2C2E731D073F/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/186C2C2E731D073F -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/186C2C2E731D073F/segmentation-1.mha\n",
            "Original Segmentation Shape: (282, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (501, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Processing patient folder: /content/drive/My Drive/129A1F8B9C12F86B\n",
            "Original CT Shape: (696, 512, 512)\n",
            "No .mha segmentation file found in im_3 for /content/drive/My Drive/129A1F8B9C12F86B. Attempting conversion...\n",
            "Running dcmqi conversion command:\n",
            " /content/dcmqi-1.2.5-linux/bin/segimage2itkimage --inputDICOM /content/drive/My Drive/129A1F8B9C12F86B/im_3/x0000.dcm --outputDirectory /content/drive/My Drive/129A1F8B9C12F86B -t mha -p segmentation\n",
            "Created .mha file: /content/drive/My Drive/129A1F8B9C12F86B/segmentation-1.mha\n",
            "Original Segmentation Shape: (283, 512, 512)\n",
            "Resampling segmentation to match CT dimensions...\n",
            "Resampled Segmentation Shape: (696, 512, 512)\n",
            "Downsampled CT Shape: (128, 128, 72)\n",
            "Downsampled Segmentation Shape: (128, 128, 72)\n",
            "\n",
            "Reached the limit of 25 processed files. Stopping.\n",
            "\n",
            "Processing complete!\n",
            "Processed 25 datasets successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install monai"
      ],
      "metadata": {
        "id": "k-RcvmNAqs3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c927cbee-11c2-4e61-affd-f77db1d0812a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.9->monai)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, monai\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed monai-1.4.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from monai.transforms import Compose, NormalizeIntensity, ToTensor\n"
      ],
      "metadata": {
        "id": "lGNspqLIqwB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multipass Unet Model Training**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "e2zXuUzhPXjO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from monai.transforms import Compose\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "# -------------------------\n",
        "# Transforms for CT Scans\n",
        "# -------------------------\n",
        "class NormalizeCT:\n",
        "    def __call__(self, ct_volume):\n",
        "        ct_volume = np.clip(ct_volume, -1000, 1000)\n",
        "        return (ct_volume + 1000) / 2000  # Scale to [0,1]\n",
        "\n",
        "class ToTensor:\n",
        "    def __call__(self, ct_volume):\n",
        "        # Convert NumPy array to tensor and add a channel dimension -> (1, D, H, W)\n",
        "        return torch.from_numpy(ct_volume).unsqueeze(0)\n",
        "\n",
        "# -------------------------\n",
        "# Custom Dataset\n",
        "# -------------------------\n",
        "class CTDataset(Dataset):\n",
        "    def __init__(self, processed_data):\n",
        "        self.data = processed_data\n",
        "        self.transform = Compose([\n",
        "            NormalizeCT(),\n",
        "            ToTensor()\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = self.data[idx]\n",
        "        ct = sample['ct_volume']       # shape: (D, H, W)\n",
        "        seg = sample['segmentation']   # shape: (D, H, W)\n",
        "\n",
        "        # Apply transforms to CT volume\n",
        "        ct = self.transform(ct)  # (1, D, H, W)\n",
        "        # For segmentation, just convert to tensor with a channel dimension\n",
        "        seg = torch.from_numpy(seg).unsqueeze(0).float()  # (1, D, H, W)\n",
        "\n",
        "        return {'ct': ct.float(), 'seg': seg.float()}\n",
        "\n",
        "# -------------------------\n",
        "# Custom Collate Function (as defined above)\n",
        "# -------------------------\n",
        "def pad_to_depth(x, target_depth):\n",
        "    current_depth = x.shape[1]\n",
        "    if current_depth < target_depth:\n",
        "        pad_amount = target_depth - current_depth\n",
        "        pad_tensor = torch.zeros(x.shape[0], pad_amount, x.shape[2], x.shape[3], device=x.device, dtype=x.dtype)\n",
        "        x = torch.cat([x, pad_tensor], dim=1)\n",
        "    return x\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    max_depth = max(sample['ct'].shape[1] for sample in batch)\n",
        "    for sample in batch:\n",
        "        sample['ct'] = pad_to_depth(sample['ct'], max_depth)\n",
        "        sample['seg'] = pad_to_depth(sample['seg'], max_depth)\n",
        "    batch_ct = torch.stack([sample['ct'] for sample in batch])\n",
        "    batch_seg = torch.stack([sample['seg'] for sample in batch])\n",
        "    return {'ct': batch_ct, 'seg': batch_seg}\n",
        "\n",
        "# -------------------------\n",
        "# Multipass 3D U-Net Model\n",
        "# -------------------------\n",
        "class MultiPassUNet3D(nn.Module):\n",
        "    def __init__(self, in_channels=2, out_channels=1, base_channels=16):\n",
        "        super(MultiPassUNet3D, self).__init__()\n",
        "        # Encoder\n",
        "        self.enc1 = self._block(in_channels, base_channels)\n",
        "        self.pool1 = nn.MaxPool3d(2)\n",
        "        self.enc2 = self._block(base_channels, base_channels*2)\n",
        "        self.pool2 = nn.MaxPool3d(2)\n",
        "        # Bridge\n",
        "        self.bridge = self._block(base_channels*2, base_channels*4)\n",
        "        # Decoder\n",
        "        self.up1 = nn.ConvTranspose3d(base_channels*4, base_channels*2, 2, stride=2)\n",
        "        self.dec1 = self._block(base_channels*4, base_channels*2)\n",
        "        self.up2 = nn.ConvTranspose3d(base_channels*2, base_channels, 2, stride=2)\n",
        "        self.dec2 = self._block(base_channels*2, base_channels)\n",
        "        # Output\n",
        "        self.out = nn.Conv3d(base_channels, out_channels, 1)\n",
        "\n",
        "    def _block(self, in_channels, features):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv3d(in_channels, features, 3, padding=1),\n",
        "            nn.BatchNorm3d(features),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv3d(features, features, 3, padding=1),\n",
        "            nn.BatchNorm3d(features),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(self.pool1(enc1))\n",
        "        bridge = self.bridge(self.pool2(enc2))\n",
        "        dec1 = self.up1(bridge)\n",
        "        dec1 = torch.cat((dec1, enc2), dim=1)\n",
        "        dec1 = self.dec1(dec1)\n",
        "        dec2 = self.up2(dec1)\n",
        "        dec2 = torch.cat((dec2, enc1), dim=1)\n",
        "        dec2 = self.dec2(dec2)\n",
        "        return self.out(dec2)\n",
        "\n",
        "# -------------------------\n",
        "# Dice Score Metric\n",
        "# -------------------------\n",
        "def dice_score(pred, target, smooth=1e-6):\n",
        "    pred = (pred > 0.5).float()\n",
        "    intersection = (pred * target).sum(dim=[1,2,3,4])\n",
        "    union = pred.sum(dim=[1,2,3,4]) + target.sum(dim=[1,2,3,4])\n",
        "    dice = (2. * intersection + smooth) / (union + smooth)\n",
        "    return dice.mean().item()\n",
        "\n",
        "# -------------------------\n",
        "# Training Setup\n",
        "# -------------------------\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiPassUNet3D().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
        "\n",
        "# Create DataLoader using our custom collate function\n",
        "dataset = CTDataset(processed_data)\n",
        "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, num_workers=2, collate_fn=custom_collate_fn)\n",
        "\n",
        "# -------------------------\n",
        "# Multipass Training Loop\n",
        "# -------------------------\n",
        "num_epochs = 50\n",
        "best_loss = float('inf')\n",
        "MODEL_NAME = \"MultiPassUNet3D\"\n",
        "SAVE_DIR = f\"/content/gdrive/My Drive/UNet Model\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "    dice_total = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "        ct = batch['ct'].to(device)   # (B, 1, D, H, W)\n",
        "        seg = batch['seg'].to(device) # (B, 1, D, H, W)\n",
        "\n",
        "        # First Pass: Blank shape context\n",
        "        blank_context = torch.zeros_like(ct)\n",
        "        input_pass1 = torch.cat([ct, blank_context], dim=1)  # (B, 2, D, H, W)\n",
        "        output_pass1 = model(input_pass1)\n",
        "        loss1 = criterion(output_pass1, seg)\n",
        "\n",
        "        # Second Pass: Use thresholded prediction from pass 1 as shape context\n",
        "        with torch.no_grad():\n",
        "            context = (torch.sigmoid(output_pass1) > 0.5).float()\n",
        "        input_pass2 = torch.cat([ct, context], dim=1)\n",
        "        output_pass2 = model(input_pass2)\n",
        "        loss2 = criterion(output_pass2, seg)\n",
        "\n",
        "        total_loss = loss1 + loss2\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        total_loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += total_loss.item()\n",
        "        dice_total += dice_score(torch.sigmoid(output_pass2), seg)\n",
        "        num_batches += 1\n",
        "\n",
        "    avg_loss = epoch_loss / len(dataloader)\n",
        "    avg_dice = dice_total / num_batches\n",
        "    scheduler.step(avg_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f} | Avg Dice Score: {avg_dice:.4f}\")\n",
        "    Avg_dice_score[epoch]=avg_dice\n",
        "    Avg_loss[epoch]=avg_loss\n",
        "\n",
        "    if avg_loss < best_loss:\n",
        "        best_loss = avg_loss\n",
        "        torch.save(model.state_dict(), f\"best_model_epoch{epoch+1}.pth\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "id": "OMXrVNr_mIjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3def6e2-08ac-470c-a5cf-600364ac9677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   0%|          | 0/25 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#dice score plot\n",
        "plt.figure(figsize(10,5))\n",
        "plt.plot(epoch,Avg_dice_score,label='Dice Score',marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Dice Score')\n",
        "plt.title('Dice Score vs Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#avg loss plot\n",
        "plt.figure(figsize(10,5))\n",
        "plt.plot(epoch,Avg_Loss,Label='Loss',marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "#inference\n",
        "# Load the trained model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = MultiPassUNet3D().to(device)\n",
        "model.load_state_dict(torch.load(\"best_model_epochX.pth\"))  # Replace with actual epoch\n",
        "model.eval()\n",
        "\n",
        "# Function to preprocess a test CT scan\n",
        "def preprocess_ct_scan(ct_path, target_shape=(128, 128, 72)):\n",
        "    # Load CT scan (assuming MHA format)\n",
        "    ct_image = sitk.ReadImage(ct_path)\n",
        "    ct_volume = sitk.GetArrayFromImage(ct_image)  # Shape: (D, H, W)\n",
        "\n",
        "    # Normalize\n",
        "    ct_volume = np.clip(ct_volume, -1000, 1000)\n",
        "    ct_volume = (ct_volume + 1000) / 2000  # Scale to [0,1]\n",
        "\n",
        "    # Resize to target shape\n",
        "    ct_tensor = torch.tensor(ct_volume, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # (1, 1, D, H, W)\n",
        "    ct_resized = F.interpolate(ct_tensor, size=target_shape, mode='trilinear', align_corners=False)\n",
        "    return ct_resized.squeeze(0)  # (1, D, H, W)\n",
        "\n",
        "# Function to run inference\n",
        "def infer(ct_tensor):\n",
        "    with torch.no_grad():\n",
        "        blank_context = torch.zeros_like(ct_tensor)  # Pass 1: blank shape context\n",
        "        input_pass1 = torch.cat([ct_tensor, blank_context], dim=1).to(device)\n",
        "        output_pass1 = model(input_pass1)\n",
        "\n",
        "        context = (torch.sigmoid(output_pass1) > 0.5).float()  # Pass 2: thresholded prediction as context\n",
        "        input_pass2 = torch.cat([ct_tensor, context], dim=1).to(device)\n",
        "        output_pass2 = model(input_pass2)\n",
        "\n",
        "    return torch.sigmoid(output_pass2).cpu().numpy()  # Convert to NumPy array\n",
        "\n",
        "# Paths to test images (update these paths)\n",
        "test1_ct_path = \"path/to/test1.mha\"\n",
        "test2_ct_path = \"path/to/test2.mha\"\n",
        "test1_seg_path = \"path/to/test1_seg.mha\"  # Ground truth segmentation\n",
        "test2_seg_path = \"path/to/test2_seg.mha\"\n",
        "\n",
        "# Preprocess test scans\n",
        "ct_test1 = preprocess_ct_scan(test1_ct_path)\n",
        "ct_test2 = preprocess_ct_scan(test2_ct_path)\n",
        "\n",
        "# Run inference\n",
        "pred_test1 = infer(ct_test1)\n",
        "pred_test2 = infer(ct_test2)\n",
        "\n",
        "# Load ground truth segmentations\n",
        "gt_test1 = sitk.GetArrayFromImage(sitk.ReadImage(test1_seg_path))  # (D, H, W)\n",
        "gt_test2 = sitk.GetArrayFromImage(sitk.ReadImage(test2_seg_path))\n",
        "\n",
        "# Plot function\n",
        "def plot_results(ct_volume, ground_truth, prediction, slice_idx):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Original CT slice\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(ct_volume[slice_idx], cmap='gray')\n",
        "    plt.title(\"CT Slice\")\n",
        "\n",
        "    # Ground truth segmentation\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(ground_truth[slice_idx], cmap='gray')\n",
        "    plt.title(\"Ground Truth Segmentation\")\n",
        "\n",
        "    # Predicted segmentation\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(prediction[slice_idx], cmap='gray')\n",
        "    plt.title(\"Predicted Segmentation\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a slice (e.g., middle slice)\n",
        "mid_slice = ct_test1.shape[1] // 2  # Depth index\n",
        "plot_results(ct_test1.squeeze().numpy(), gt_test1, pred_test1.squeeze(), mid_slice)\n",
        "plot_results(ct_test2.squeeze().numpy(), gt_test2, pred_test2.squeeze(), mid_slice)\n"
      ],
      "metadata": {
        "id": "gb7754hvMfYr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}